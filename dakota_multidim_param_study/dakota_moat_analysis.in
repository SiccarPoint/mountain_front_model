#part 2 of BRaKE Dakota workflow

#part 1 did the parameter study in parallel, part 2 is
#now to analysze the data and get the response functions

#Call with: 
# $ dakota -i dakota_moat_analysis.in -o dakota_moat_analysis.out &> analysis.log

environment,
  tabular_data,
    tabular_data_file = 'moat_analysis_output.dat'

method,
  psuade_moat
    samples = 9
    partitions = 3
    seed = 500
	
variables,
  continuous_design = 8
    lower_bounds = 0.0 1.0 0.0000000000001 0.0000000000001 10000 0.001 0.0 0.00005
    upper_bounds = 1.0 6.0 0.0000000001 0.0000000001 1.0 100000 6.0 100 0.001
	descriptors = 'gamma' 'block_size' 'k_bed' 'k_block' 'delay' 'z_0' 'tau_c' 'bl_drop'

interface,
  fork
  id_interface = '0'
  analysis_driver = 'python ./dakota_analysis_driver.py'
  parameters_file = 'params.in'
  results_file = 'results.out'
  work_directory
    named 'run'
    directory_tag
    directory_save
  file_save

responses,
  response_functions = 8
  response_descriptors = 'tot-vol-lost' 'fin-max-elev' 'fin-mean-elev' 'fin-std-elev' 'fin-max-slo' 'fin-mean-slo' 'fin-std-slo' 'tot-blocks'
  no_gradients
  no_hessians
